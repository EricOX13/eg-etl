{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Picked up JAVA_TOOL_OPTIONS: -Dfile.encoding=ISO-8859-1\n",
      "Picked up JAVA_TOOL_OPTIONS: -Dfile.encoding=ISO-8859-1\n",
      "24/02/28 18:41:28 WARN Utils: Your hostname, Erics-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 172.20.10.2 instead (on interface en0)\n",
      "24/02/28 18:41:28 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Users/ericyeung/Library/Caches/pypoetry/virtualenvs/evergreen-DHscqOYO-py3.11/lib/python3.11/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/ericyeung/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/ericyeung/.ivy2/jars\n",
      "org.apache.iceberg#iceberg-spark-runtime-3.4_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-5c71d068-3641-436d-a3a1-746a45be8453;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.iceberg#iceberg-spark-runtime-3.4_2.12;1.3.0 in central\n",
      ":: resolution report :: resolve 119ms :: artifacts dl 5ms\n",
      "\t:: modules in use:\n",
      "\torg.apache.iceberg#iceberg-spark-runtime-3.4_2.12;1.3.0 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   1   |   0   |   0   |   0   ||   1   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-5c71d068-3641-436d-a3a1-746a45be8453\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 1 already retrieved (0kB/5ms)\n",
      "24/02/28 18:41:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240228_184133\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "from datetime import datetime\n",
    "\n",
    "warehouse_path = \"./warehouse\"\n",
    "iceberg_spark_jar  = 'org.apache.iceberg:iceberg-spark-runtime-3.4_2.12:1.3.0'\n",
    "catalog_name = \"demo\"\n",
    "\n",
    "# Setup iceberg config\n",
    "conf = (\n",
    "    SparkConf()\n",
    "    .setAppName(\"EvergreenApp\")\n",
    "    .set(\n",
    "        \"spark.sql.extensions\",\n",
    "        \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\",\n",
    "    )\n",
    "    .set(f\"spark.sql.catalog.{catalog_name}\", \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "    .set(\"spark.jars.packages\", iceberg_spark_jar)\n",
    "    .set(f\"spark.sql.catalog.{catalog_name}.warehouse\", warehouse_path)\n",
    "    .set(f\"spark.sql.catalog.{catalog_name}.type\", \"hadoop\")\n",
    "    .set(\"spark.sql.defaultCatalog\", catalog_name)\n",
    ")\n",
    "\n",
    "sc = SparkSession.builder.master(\"local\").config(conf=conf).getOrCreate()\n",
    "\n",
    "batch = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps Iceberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conf.init_schema import init_database\n",
    "\n",
    "init_database(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Postcode related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extract_utils import extract_csv\n",
    "\n",
    "df_postcode_lookup = extract_csv(sc, \"src_data/National_Statistics_Postcode_Lookup_Latest_Centroids.csv\")\n",
    "df_postcode_lookup.printSchema()\n",
    "df_postcode_lookup.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transform.postcode import PostcodeTransformer\n",
    "df_postcode = PostcodeTransformer.transform(df_postcode_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_postcode.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_postcode.write.mode(\"overwrite\").insertInto(f\"{catalog_name}.db.postcode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DateType\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.types import StructType\n",
    "from pyspark.sql.types import StructField\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "users_schema = StructType(\n",
    "[StructField(\"email\", StringType(), True),\n",
    " StructField(\"givenName\", StringType(), True),\n",
    " StructField(\"familyName\", StringType(), True),\n",
    " StructField(\"sex\", StringType(), True),\n",
    " StructField(\"dateOfBirth\", StringType(), True),\n",
    " StructField(\"address\", StructType([\n",
    "     StructField(\"street\", StringType(), True),\n",
    "     StructField(\"postcode\", StringType(), True)]), True),]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from extract_utils import extract_json\n",
    "\n",
    "df_users = extract_json(sc, \"src_data/users1.json\", users_schema)\n",
    "df_users.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-28 18:41:45,856 - eg-etl - INFO - [validation_utils.py:21 -   check_data_quality() ] - Original dataframe count: 3\n",
      "\n",
      "2024-02-28 18:41:45,856 - eg-etl - INFO - [validation_utils.py:21 -   check_data_quality() ] - Original dataframe count: 3\n",
      "\n",
      "2024-02-28 18:41:45,856 - eg-etl - INFO - [validation_utils.py:21 -   check_data_quality() ] - Original dataframe count: 3\n",
      "\n",
      "+---------------------------+---------+----------+----+-----------+---------------+---+\n",
      "|email                      |givenName|familyName|sex |dateOfBirth|address        |_id|\n",
      "+---------------------------+---------+----------+----+-----------+---------------+---+\n",
      "|Regina80@hotmail.com       |Regina   |Tremblay  |M   |1982-08-09 |{NULL, CV4 9RE}|0  |\n",
      "|Vickie.Hilpert2@hotmail.com|Vickie   |Hilpert   |F   |1988-02-28 |{NULL, GU342TZ}|1  |\n",
      "|Gloria69@hotmail.com       |NULL     |NULL      |NULL|NULL       |{NULL, NULL}   |2  |\n",
      "+---------------------------+---------+----------+----+-----------+---------------+---+\n",
      "\n",
      "+---------------------------+---------+----------+----+-----------+---------------+---+\n",
      "|email                      |givenName|familyName|sex |dateOfBirth|address        |_id|\n",
      "+---------------------------+---------+----------+----+-----------+---------------+---+\n",
      "|Regina80@hotmail.com       |Regina   |Tremblay  |M   |1982-08-09 |{NULL, CV4 9RE}|0  |\n",
      "|Vickie.Hilpert2@hotmail.com|Vickie   |Hilpert   |F   |1988-02-28 |{NULL, GU342TZ}|1  |\n",
      "|Gloria69@hotmail.com       |NULL     |NULL      |NULL|NULL       |{NULL, NULL}   |2  |\n",
      "+---------------------------+---------+----------+----+-----------+---------------+---+\n",
      "\n",
      "2024-02-28 18:41:46,476 - eg-etl - DEBUG - [validation_utils.py:76 -      check_mandatory() ] - givenName\n",
      "\n",
      "2024-02-28 18:41:46,476 - eg-etl - DEBUG - [validation_utils.py:76 -      check_mandatory() ] - givenName\n",
      "\n",
      "2024-02-28 18:41:46,476 - eg-etl - DEBUG - [validation_utils.py:76 -      check_mandatory() ] - givenName\n",
      "\n",
      "2024-02-28 18:41:46,827 - eg-etl - DEBUG - [validation_utils.py:83 -      check_mandatory() ] - {2}\n",
      "\n",
      "2024-02-28 18:41:46,827 - eg-etl - DEBUG - [validation_utils.py:83 -      check_mandatory() ] - {2}\n",
      "\n",
      "2024-02-28 18:41:46,827 - eg-etl - DEBUG - [validation_utils.py:83 -      check_mandatory() ] - {2}\n",
      "\n",
      "+---------------------------+---------+----------+----+-----------+---------------+---+\n",
      "|email                      |givenName|familyName|sex |dateOfBirth|address        |_id|\n",
      "+---------------------------+---------+----------+----+-----------+---------------+---+\n",
      "|Regina80@hotmail.com       |Regina   |Tremblay  |M   |1982-08-09 |{NULL, CV4 9RE}|0  |\n",
      "|Vickie.Hilpert2@hotmail.com|Vickie   |Hilpert   |F   |1988-02-28 |{NULL, GU342TZ}|1  |\n",
      "|Gloria69@hotmail.com       |NULL     |NULL      |NULL|NULL       |{NULL, NULL}   |2  |\n",
      "+---------------------------+---------+----------+----+-----------+---------------+---+\n",
      "\n",
      "2024-02-28 18:41:47,141 - eg-etl - DEBUG - [validation_utils.py:76 -      check_mandatory() ] - familyName\n",
      "\n",
      "2024-02-28 18:41:47,141 - eg-etl - DEBUG - [validation_utils.py:76 -      check_mandatory() ] - familyName\n",
      "\n",
      "2024-02-28 18:41:47,141 - eg-etl - DEBUG - [validation_utils.py:76 -      check_mandatory() ] - familyName\n",
      "\n",
      "2024-02-28 18:41:47,695 - eg-etl - DEBUG - [validation_utils.py:83 -      check_mandatory() ] - {2}\n",
      "\n",
      "2024-02-28 18:41:47,695 - eg-etl - DEBUG - [validation_utils.py:83 -      check_mandatory() ] - {2}\n",
      "\n",
      "2024-02-28 18:41:47,695 - eg-etl - DEBUG - [validation_utils.py:83 -      check_mandatory() ] - {2}\n",
      "\n",
      "+---------------------------+---------+----------+----+-----------+---------------+---+\n",
      "|email                      |givenName|familyName|sex |dateOfBirth|address        |_id|\n",
      "+---------------------------+---------+----------+----+-----------+---------------+---+\n",
      "|Regina80@hotmail.com       |Regina   |Tremblay  |M   |1982-08-09 |{NULL, CV4 9RE}|0  |\n",
      "|Vickie.Hilpert2@hotmail.com|Vickie   |Hilpert   |F   |1988-02-28 |{NULL, GU342TZ}|1  |\n",
      "|Gloria69@hotmail.com       |NULL     |NULL      |NULL|NULL       |{NULL, NULL}   |2  |\n",
      "+---------------------------+---------+----------+----+-----------+---------------+---+\n",
      "\n",
      "2024-02-28 18:41:48,133 - eg-etl - DEBUG - [validation_utils.py:76 -      check_mandatory() ] - sex\n",
      "\n",
      "2024-02-28 18:41:48,133 - eg-etl - DEBUG - [validation_utils.py:76 -      check_mandatory() ] - sex\n",
      "\n",
      "2024-02-28 18:41:48,133 - eg-etl - DEBUG - [validation_utils.py:76 -      check_mandatory() ] - sex\n",
      "\n",
      "2024-02-28 18:41:48,441 - eg-etl - DEBUG - [validation_utils.py:83 -      check_mandatory() ] - {2}\n",
      "\n",
      "2024-02-28 18:41:48,441 - eg-etl - DEBUG - [validation_utils.py:83 -      check_mandatory() ] - {2}\n",
      "\n",
      "2024-02-28 18:41:48,441 - eg-etl - DEBUG - [validation_utils.py:83 -      check_mandatory() ] - {2}\n",
      "\n",
      "+---------------------------+---------+----------+----+-----------+---------------+---+\n",
      "|email                      |givenName|familyName|sex |dateOfBirth|address        |_id|\n",
      "+---------------------------+---------+----------+----+-----------+---------------+---+\n",
      "|Regina80@hotmail.com       |Regina   |Tremblay  |M   |1982-08-09 |{NULL, CV4 9RE}|0  |\n",
      "|Vickie.Hilpert2@hotmail.com|Vickie   |Hilpert   |F   |1988-02-28 |{NULL, GU342TZ}|1  |\n",
      "|Gloria69@hotmail.com       |NULL     |NULL      |NULL|NULL       |{NULL, NULL}   |2  |\n",
      "+---------------------------+---------+----------+----+-----------+---------------+---+\n",
      "\n",
      "2024-02-28 18:41:48,617 - eg-etl - DEBUG - [validation_utils.py:76 -      check_mandatory() ] - dateOfBirth\n",
      "\n",
      "2024-02-28 18:41:48,617 - eg-etl - DEBUG - [validation_utils.py:76 -      check_mandatory() ] - dateOfBirth\n",
      "\n",
      "2024-02-28 18:41:48,617 - eg-etl - DEBUG - [validation_utils.py:76 -      check_mandatory() ] - dateOfBirth\n",
      "\n",
      "2024-02-28 18:41:48,818 - eg-etl - DEBUG - [validation_utils.py:83 -      check_mandatory() ] - {2}\n",
      "\n",
      "2024-02-28 18:41:48,818 - eg-etl - DEBUG - [validation_utils.py:83 -      check_mandatory() ] - {2}\n",
      "\n",
      "2024-02-28 18:41:48,818 - eg-etl - DEBUG - [validation_utils.py:83 -      check_mandatory() ] - {2}\n",
      "\n",
      "2024-02-28 18:41:48,819 - eg-etl - INFO - [validation_utils.py:85 -      check_mandatory() ] - Failed Mandatory column checking record count: 1\n",
      "\n",
      "2024-02-28 18:41:48,819 - eg-etl - INFO - [validation_utils.py:85 -      check_mandatory() ] - Failed Mandatory column checking record count: 1\n",
      "\n",
      "2024-02-28 18:41:48,819 - eg-etl - INFO - [validation_utils.py:85 -      check_mandatory() ] - Failed Mandatory column checking record count: 1\n",
      "\n",
      "{2}\n",
      "2024-02-28 18:41:49,459 - eg-etl - INFO - [validation_utils.py:146 -         check_format() ] - Failed Format checking record count: 3\n",
      "\n",
      "2024-02-28 18:41:49,459 - eg-etl - INFO - [validation_utils.py:146 -         check_format() ] - Failed Format checking record count: 3\n",
      "\n",
      "2024-02-28 18:41:49,459 - eg-etl - INFO - [validation_utils.py:146 -         check_format() ] - Failed Format checking record count: 3\n",
      "\n",
      "2024-02-28 18:41:49,460 - eg-etl - INFO - [validation_utils.py:36 -   check_data_quality() ] - Total failed record count: 3\n",
      "\n",
      "2024-02-28 18:41:49,460 - eg-etl - INFO - [validation_utils.py:36 -   check_data_quality() ] - Total failed record count: 3\n",
      "\n",
      "2024-02-28 18:41:49,460 - eg-etl - INFO - [validation_utils.py:36 -   check_data_quality() ] - Total failed record count: 3\n",
      "\n",
      "2024-02-28 18:41:49,461 - eg-etl - INFO - [validation_utils.py:38 -   check_data_quality() ] - {0, 1, 2}\n",
      "\n",
      "2024-02-28 18:41:49,461 - eg-etl - INFO - [validation_utils.py:38 -   check_data_quality() ] - {0, 1, 2}\n",
      "\n",
      "2024-02-28 18:41:49,461 - eg-etl - INFO - [validation_utils.py:38 -   check_data_quality() ] - {0, 1, 2}\n",
      "\n",
      "2024-02-28 18:41:50,082 - eg-etl - INFO - [validation_utils.py:46 -   check_data_quality() ] - Deduplicated record count: 0\n",
      "\n",
      "2024-02-28 18:41:50,082 - eg-etl - INFO - [validation_utils.py:46 -   check_data_quality() ] - Deduplicated record count: 0\n",
      "\n",
      "2024-02-28 18:41:50,082 - eg-etl - INFO - [validation_utils.py:46 -   check_data_quality() ] - Deduplicated record count: 0\n",
      "\n",
      "2024-02-28 18:41:50,258 - eg-etl - INFO - [load_utils.py:11 -        write_to_json() ] - write to json path: output/validation/Fail_Record_20240228_184133.json\n",
      "\n",
      "2024-02-28 18:41:50,258 - eg-etl - INFO - [load_utils.py:11 -        write_to_json() ] - write to json path: output/validation/Fail_Record_20240228_184133.json\n",
      "\n",
      "2024-02-28 18:41:50,258 - eg-etl - INFO - [load_utils.py:11 -        write_to_json() ] - write to json path: output/validation/Fail_Record_20240228_184133.json\n",
      "\n",
      "2024-02-28 18:41:50,768 - eg-etl - INFO - [load_utils.py:13 -        write_to_json() ] - write to json path: output/validation/Fail_Record_20240228_184133.json completed!\n",
      "\n",
      "2024-02-28 18:41:50,768 - eg-etl - INFO - [load_utils.py:13 -        write_to_json() ] - write to json path: output/validation/Fail_Record_20240228_184133.json completed!\n",
      "\n",
      "2024-02-28 18:41:50,768 - eg-etl - INFO - [load_utils.py:13 -        write_to_json() ] - write to json path: output/validation/Fail_Record_20240228_184133.json completed!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from validation_utils import check_data_quality\n",
    "\n",
    "df_validated = check_data_quality(df_users, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_validated.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
